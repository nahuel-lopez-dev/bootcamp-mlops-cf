<section id="inicio" align="center">
    <h1>Proyecto Final</h1>
    <h2 align="center">Bootcamp de MLOps</h2>
    <img width=500 src="./images/MLOps.png"/>
</section>

<h3>Proyecto para el Bootcamp de MLOps en <a href="https://codigofacilito.com">C√≥digo Facilito</a></h3>

<h3>L√≠der del bootcamp: <a href="https://www.linkedin.com/in/antonioferegrino/">Antonio Feregrino, Senior MLOps Engineer at simply Business</a></h3>

<h3>Tabla de Contenidos:</h3>

- [**Informaci√≥n del proyecto**](#informaci√≥n-del-proyecto) üìÅ
- [**Version 1.0.0**](#version-100) ‚úÖ
- [**Fuentes de datos**](#fuentes-de-datos) üóÑÔ∏è
- [**Prerrequisitos**](#prerrequisitos) üìù
- [**Herramientas y tecnolog√≠as**](#herramientas-y-tecnolog√≠as) üõ†Ô∏è
- [**Instalaci√≥n y configuraci√≥n del Entorno**](#instalaci√≥n-y-configuraci√≥n-del-entorno) üíª
- [**Desarrollo**](#desarrollo) ‚öôÔ∏è
- [**Screenshots**](#screenshots) üì∏
- [**Informaci√≥n adicional**](#informaci√≥n-adicional) ü™ß
- [**Agradecimientos**](#agradecimientos) üëãüèΩ
- [**Autores**](#autores) ‚ö°ü™™

### **Informaci√≥n del proyecto**

Proyecto final para el bootcamp de MLOps de [C√≥digo Facilito](https://codigofacilito.com), donde se va a construir un ...

- Objetivo General:
  
  Construir un sistema de ETL donde se ingesta en una tabla de Snowflake la informaci√≥n de las ligas de f√∫tbol m√°s importantes de Europa

- Requisitos Espec√≠ficos:
  - Extraer datos de m√∫ltiples fuentes (p√°ginas web) con python.
  - Transformar estos datos con Python para obtener un dataset limpio.
  - Crear un DAG en Airflow, desplegado de manera local con Astro CLI, para que dos veces por semana vaya a la p√°gina web, extraiga la informaci√≥n, la transforme, y luego se cargue en una tabla en Snowflake.
  - Una vez hecho esto, se podr√° hacer todo tipo de trabajos de anal√≠tica de datos, ya sea top five de los equipos con m√°s goles, con menos goles, con mayor partidos ganados, etc.

- Alcance:
  
  Para el p√∫blico en general, no se busca resolver una problem√°tica en particular, sino practicar algunas de las herramientas vistas en el bootcamp para mostrar el desarrollo y despliegue a producci√≥n de un modelo de ML.


### **Version 1.0.0**

[![Demo](https://img.shields.io/badge/Demo_(En_proceso)-informational?style=for-the-badge&logo=vercel&logoColor=fff&color=23272d)](https://github.com/Nahuel-DevOne/data-engineering-cf)

### **Fuentes de datos**

- df_ligas.csv
- team_table.csv

### **Prerrequisitos**

Lista de software y herramientas, que necesitas para instalar y ejecutar este proyecto:

- WSL
- Git
- GitHub
- Docker
- Python
- Snowflake
- Airflow
- Astro CLI

### **Herramientas y tecnolog√≠as**

Tecnolog√≠as utilizadas para construir el proyecto:

- [Git](https://git-scm.com/) - El controlador de versiones utilizado
- [GitHub](https://github.com/) - La plataforma de desarrollo colaborativo, donde se aloja este proyecto.
- [Docker](https://www.docker.com/) - La tecnolog√≠a de contenedores utilizada para manejar una imagen de airflow.
- [Python](https://www.python.org/) - El lenguaje de programaci√≥n utilizado.
- [Pandas](https://pandas.pydata.org/) - Una librer√≠a  de Python para la manipulaci√≥n y el an√°lisis de los datos.
- [SQL](https://www.postgresql.org) - El lenguaje de consulta utilizado para bases de datos relacionales.
- [Snowflake](https://www.snowflake.com/es/) - La plataforma de almacenamiento de datos basada en la nube que fue utilizada. 
- [Airflow](https://airflow.apache.org/) - La plataforma de gesti√≥n de flujo (un orquestador) utilizada.
- [Astronomer](https://docs.astronomer.io/) - Aplicaci√≥n de software como servicio (SaaS) que posee y ejecuta recursos de Astro. En este caso se utiliza Astro CLI para desplegar y correr la UI de Airflow.

### **Instalaci√≥n y configuraci√≥n del Entorno** 

Instalaciones y configuraciones del entorno

`Python`

Instalar Python: [Instalaci√≥n](https://www.python.org/downloads/)

```bash
# Instalar seg√∫n tu sistema operativo
```

`WSL`

Instalar WSL: [Instalaci√≥n](https://learn.microsoft.com/es-es/windows/wsl/install)

```bash
# Por terminal
wsl --update
wsl.exe --install
```

`Docker`

Instalar Docker: [Instalaci√≥n](https://www.docker.com/)

```bash
Seguir los pasos de instalaci√≥n seg√∫n tu sistema operativo.
Requiere de WSL para Windows
```

`Astro CLI`

```bash
# Instalar Astro CLI por medio de WSL
curl -sSL install.astronomer.io | sudo bash -s

# En el Visual Studio Code o el editor de tu preferencia, inicializar Astro y todos los paquetes necesarios
astro dev init

# Levantar la UI de Airflow
astro dev start o bien sudo astro dev start en caso de acceso denegado  
```

`Snowflake`

Crear cuenta en: [Snowflake](https://www.snowflake.com/es/)

```python
# Dise√±o del Modelo de Datos | Esquema de Snowflake:

# 1. Nombre de las configuraciones iniciales

Datawarehouse = normal_wh

Database = leagues

Stage = demo_stage

# 2. Crear un nuevo Worksheet desde la UI de Snowflake

# 3. Aplicar las siguientes queries desde tu Worksheet para crear tu DWH , DB y STAGE

# SET UP DWH , DATABASE and STAGE
 
CREATE or REPLACE warehouse normal_wh warehouse_size=XSMALL initially_suspended=true;
CREATE DATABASE leagues; 
CREATE STAGE "LEAGUES"."PUBLIC".demo_stage;

# 4. Crear una nueva tabla para recibir los datos de cada liga

# CREATE NEW TABLE
 
CREATE OR REPLACE TABLE football_leagues (
id         VARCHAR (30) NOT NULL,
equipo     VARCHAR (30) NOT NULL,
Jugados    INTEGER NOT NULL,
ganados    INTEGER NOT NULL,
empatados  INTEGER NOT NULL,
perdidos   INTEGER NOT NULL,
gf         INTEGER NOT NULL,
gc         INTEGER NOT NULL,
diff       INTEGER NOT NULL,
puntos     INTEGER NOT NULL,
liga       VARCHAR (30) NOT NULL,
created_at VARCHAR (30) NOT NULL
);

```

`Airflow`

Corre con una imagen de Docker que se levanta y ejecuta con Astro CLI

```bash
Se debe realizar la configuraci√≥n de conexi√≥n con Snowflake y se generan las variables de entorno para proteger los datos sensibles de la misma.
A su vez, se configura la automatizaci√≥n, para repetir el proceso de ETL algunas veces en la semana.
```

---

### **Desarrollo**

`Extracci√≥n de Datos`

Utilizando Python y la librer√≠a de Pandas, se genera un dataframe con los datos de las ligas de Europa, usandola URL de cada liga y de su respectivo pa√≠s.
De esta manera, se extraen los datos en un notebook de forma que luego se pueden trabajar para ser transformados.
 
`Transformaci√≥n de Datos`

Ya cargado el dataframe, con los datos en crudo, se limpian y se transforman en datos √∫tiles con Python y Pandas.
Se realiza un proceso llamado feature Engineering (o ingenier√≠a de variables) para dejarlos datos en el formato que se necesitan para ser cargados.

`Carga de Datos`

Se trabaja en el almac√©n de los datos, Snowflake. Para ello se crea el stage (que es un √°rea de almacenamiento temporal para archivos de datos antes de cargarlos en tablas) donde se pasa la base de datos con sus esquemas. Luego se crea la tabla de f√∫tbol ‚Äúfootball_leagues‚Äù (pasos detallados en la configuraci√≥n). 
En este punto Airflow est√° funcional y listo para conectarse con Snowflake. 

`Funciones para extracci√≥n y transformaci√≥n`

```python
import pandas as pd
import time
import random
import os
from datetime import datetime

def get_data(url,liga):
    
    tiempo = [1,3,2]
    time.sleep(random.choice(tiempo)) # para no recargar el servidor
    df = pd.read_html(url)
    df=pd.concat([df[0],df[1]],ignore_index=True,axis=1)
    df=df.rename(columns={0:'EQUIPO',1:'J', 2:'G', 3:'E', 4:'P', 5:'GF', 6:'GC', 7:'DIF', 8:'PTS'})
    df['EQUIPO']=df['EQUIPO'].apply(lambda x: x[5:] if x[:2].isnumeric()==True else x[4:])
    df['LIGA'] = liga

    # Obtener la hora de extracci√≥n
    run_date = datetime.now()
    run_date = run_date.strftime("%Y-%m-%d")
    df['CREATED_AT'] = run_date

    return df

def data_processing(df):

    df_spain=get_data(df['URL'][0],df['LIGA'][0])
    df_premier=get_data(df['URL'][1],df['LIGA'][1])
    df_italy=get_data(df['URL'][2],df['LIGA'][2])
    df_germany=get_data(df['URL'][3],df['LIGA'][3])
    df_francia=get_data(df['URL'][4],df['LIGA'][4])
    df_portugal=get_data(df['URL'][5],df['LIGA'][5])
    df_holanda=get_data(df['URL'][6],df['LIGA'][6])

    df_final=pd.concat([df_spain,df_premier,df_italy,df_francia,df_portugal,df_holanda],ignore_index=False)

    return df_final

```
Al finalizar el proceso de ETL, quedan cargados en una tabla de Snowflake todos los datos limpios y transformados listos para ser utilizados.
La ventaja de estar usando Airflow para orquestar el proceso, es que este trabajo queda automatizado y los datos en Snowflake van a ser actualizados peri√≥dicamente, seg√∫n como se haya configurado. Esto se supone fundamental, en un contexto donde es necesario contar con los datos los m√°s actualizados posibles, muchas veces para informes y toma de decisiones.


---

### **Screenshots**

En proceso...

---

### **Informaci√≥n adicional**

No es la intenci√≥n de este proyecto resolver una problem√°tica en espec√≠fico, sino que el fin es mostrar como se podr√≠a hacer el despliegue a producci√≥n de un modelo de ML, llevando a cabo las mejores practicas de MLOps, utilizando varias de las herramientas y tecnolog√≠as vistas en el bootcamp, mostrando la vital importancia del rol de un MLOps dentro de un equipo de data.

---

### **Agradecimientos**

- En especial, agradecimiento a C√≥digo Facilito por la excelente experiencia del bootcamp, la entrega y el compromiso permanente con toda su comunidad, que se extiende m√°s all√° del √°mbito acad√©mico y son un ejemplo de plataforma educativa a nivel internacional.
- Agradecimientos al l√≠der del bootcamp Antonio Feregrino por dise√±ar los contenidos, y a todos los profesores y el equipo que conforman C√≥digo facilito, brindando su apoyo y conocimiento para lograr la mejor experiencia educativa.

---

### **Autores**

<p align="center">
  <a href="https://git.io/typing-svg"><img src="https://readme-typing-svg.demolab.com?font=Fira+Code&weight=500&size=21&pause=1000&color=C2D9F8&width=435&lines=¬°Hola+mundo!+Soy+Nahuel.;Un+apasionado+Data+Engineer;y+Python+Developer‚ö°." alt="Typing SVG" /></a>
</p>

<h3>¬°Hola, mi nombre es <b>Nahuel</b> üëãüèΩ!</h3>

- Soy de Buenos Aires (Argentina).
- Estudio Ingenier√≠a en sistemas.
- Me gusta leer y estudiar sobre diversos temas, explorar nuevas tecnolog√≠as y resolver problemas.
- Me desempe√±o como Data Engineer en NTT Data, pero en mi trabajo diario hago tanto ingenier√≠a de datos como ciencia de datos y machine learning.
- Tambi√©n tengo formaci√≥n en desarrollo full Stack con JavaScript y Python.

üí¨ Si√©ntete libre de ponerte en contacto conmigo.

[![Contact Me](https://img.shields.io/badge/Gmail-informational?style=for-the-badge&logo=Mail.Ru&logoColor=fff&color=c6362c)](mailto:nahue.developer1@gmail.com)
[![LinkedId](https://img.shields.io/badge/LinkedIn-informational?style=for-the-badge&logo=linkedin&logoColor=fff&color=0274b3)](https://www.linkedin.com/in/nahuel-developer/)
[![GitHub Profile](https://img.shields.io/badge/GitHub-informational?style=for-the-badge&logo=GitHub&logoColor=fff&color=343941)](https://github.com/Nahuel-DevOne)
[![Linktree](https://img.shields.io/badge/-Linktree-323330?style=for-the-badge&logo=linktree&logoColor=#41e45f)](https://linktr.ee/nahuel.lopez)

<br>

<p align="center">
  <a href="https://git.io/typing-svg"><img src="https://readme-typing-svg.demolab.com?font=Fira+Code&weight=500&size=21&pause=1000&color=C2D9F8&width=435&lines=¬°Hola+mundo!+Soy+Gabriel.;Un+apasionado+Data+Scientist;y+Geof√≠sico‚ö°." alt="Typing SVG" /></a>
</p>

<h3>¬°Hola, mi nombre es <b>Gabriel</b> üëãüèΩ!</h3>

- Soy de ...
- Estoy haciendo un doctorado en ...
- ...
- Me desempe√±o como Data Scientist en NTT Data ...
- Tambi√©n tengo formaci√≥n en ...

üí¨ Si√©ntete libre de ponerte en contacto conmigo.

[![Contact Me](https://img.shields.io/badge/Gmail-informational?style=for-the-badge&logo=Mail.Ru&logoColor=fff&color=c6362c)](mailto:nahue.developer1@gmail.com)
[![LinkedId](https://img.shields.io/badge/LinkedIn-informational?style=for-the-badge&logo=linkedin&logoColor=fff&color=0274b3)](https://www.linkedin.com/in/nahuel-developer/)
[![GitHub Profile](https://img.shields.io/badge/GitHub-informational?style=for-the-badge&logo=GitHub&logoColor=fff&color=343941)](https://github.com/Nahuel-DevOne)
[![Linktree](https://img.shields.io/badge/-Linktree-323330?style=for-the-badge&logo=linktree&logoColor=#41e45f)](https://linktr.ee/nahuel.lopez)

Desarrollado con üíô por [**Nahuel, Data Engineer**](https://linktr.ee/nahuel.lopez) y [**Gabriel Gelpi, Data Scientist**](https://linktr.ee/nahuel.lopez).

[**‚ö°Ir al inicio‚ö°**](#inicio)

---

